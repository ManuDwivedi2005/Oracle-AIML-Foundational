# ðŸŽ“ Supervised Learning: Linear Regression

Hello, and welcome to this lesson on **Supervised Learning**.  
In this lesson, weâ€™ll focus specifically on **Linear Regression** â€” a key method in supervised learning.

---

## ðŸ§  What is Supervised Learning?

**Supervised learning** is a type of machine learning where the model learns from **labeled data**.  
It learns the **mapping** between input features and corresponding output values.

---

## ðŸ’¡ Real-World Applications of Supervised Learning

Here are some common use cases:

- ðŸ  **House Price Prediction**  
  - **Input**: House size (in sq. ft.)  
  - **Output**: Predicted house price

- ðŸ¥ **Cancer Detection**  
  - **Input**: Medical data  
  - **Output**: Tumor type (malignant or benign)

- ðŸ›ï¸ **Sentiment Analysis**  
  - **Input**: Customer reviews  
  - **Output**: Sentiment label (positive, negative, or neutral)

- ðŸ“ˆ **Stock Price Prediction**  
  - **Input**: Opening price, closing price, volume traded  
  - **Output**: Next-day stock price

---

## ðŸ” How Supervised Learning Works

Supervised learning works like **a teacher guiding a student**:
- We train the model with historical data (input-output pairs).
- The model **learns the relationship** between features and labels.
- This learned mapping can then be used to make **future predictions**.

---

## ðŸ”£ Types of Supervised Learning

- **Regression**: Output is **continuous** (e.g., price, temperature)
- **Classification**: Output is **categorical** (e.g., spam/not spam)

---

## ðŸ“Š Linear Regression: Predicting House Prices

Let's understand linear regression using an example.

### ðŸŽ¯ Goal:
Predict **house price** based on **house size**.

| House Size (sq ft) | Price ($) |
|---------------------|-----------|
| 1,000               | 300,000   |
| 1,200               | 340,000   |
| 1,500               | 400,000   |
| 1,800               | 460,000   |

- **Input (Feature)**: House size (independent variable)
- **Output (Label)**: Price (dependent variable)
- A single row is a **training example** (or tuple)

This data forms the **training dataset**.

---

## ðŸ“ˆ Visualizing the Data

When plotted as a **scatter plot**:
- X-axis: House size  
- Y-axis: House price  
- The data points show a **positive correlation**: larger houses â†’ higher prices.

We try to draw a **best-fit line** through these points.

---

## âž— The Regression Line

The equation of the line is:

f(x) = w * x + b


Where:
- `f(x)` is the predicted price
- `x` is the house size
- `w` is the **slope** (rate of price increase per sq. ft.)
- `b` is the **bias** (y-intercept)

- Changing `w` tilts the line
- Changing `b` shifts the line up/down

---

## ðŸ“‰ Training the Model

The linear regression algorithm:
1. Starts with random values for `w` and `b`
2. Predicts outputs using `f(x)`
3. Measures the **error** (difference between actual and predicted)
4. Calculates the **loss** (e.g., squared error)
5. Adjusts `w` and `b` to **minimize the loss**
6. Repeats this process iteratively (gradient descent)

> âœ… When loss is minimized, we have the **best-fit line**.

---

## ðŸ“Œ Summary

- We **train** a regression model using input-output pairs.
- The model **learns a function** `f(x) = wx + b`.
- This function is used for **prediction**.
- For example, input `1,100 sq ft` â†’ model predicts price using the learned function.

Thanks for watching!


